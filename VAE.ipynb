{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOyOci4Ki_xk"
      },
      "source": [
        "# Training a Variational Auto-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "aMYNkjbEL7gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Loss Functions\n"
      ],
      "metadata": {
        "id": "WbKzJ5D2MSmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "def loss_func(encoder_mu, encoder_log_variance):\n",
        "    def vae_reconstruction_loss(y_true, y_predict):\n",
        "        reconstruction_loss_factor = 1000\n",
        "        reconstruction_loss = keras.backend.mean(keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
        "        return reconstruction_loss_factor * reconstruction_loss\n",
        "\n",
        "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
        "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_kl_loss_metric(y_true, y_predict):\n",
        "        kl_loss = -0.5 * keras.backend.sum(1.0 + encoder_log_variance - keras.backend.square(encoder_mu) - keras.backend.exp(encoder_log_variance), axis=1)\n",
        "        return kl_loss\n",
        "\n",
        "    def vae_loss(y_true, y_predict):\n",
        "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
        "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
        "\n",
        "        loss = reconstruction_loss + kl_loss\n",
        "        return loss\n",
        "\n",
        "    return vae_loss\n",
        "\n",
        "def sampling(mu_log_variance):\n",
        "    mu, log_variance = mu_log_variance\n",
        "    epsilon = keras.backend.random_normal(shape=keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
        "    random_sample = mu + keras.backend.exp(log_variance/2) * epsilon\n",
        "    return random_sample\n"
      ],
      "metadata": {
        "id": "YlF8ZRF-MXjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_space_dim = 2\n",
        "input_shape = (9 , 9 , 1)"
      ],
      "metadata": {
        "id": "Z3u1sENkMdO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def autoencoder(lr = 1):\n",
        "    #Encoder\n",
        "    encoder_input = layers.Input(shape=(input_shape), name=\"encoder_input\")\n",
        "    shape_before_flatten = keras.backend.int_shape(encoder_input)[1:]\n",
        "    encoder_flatten = layers.Flatten()(encoder_input)\n",
        "    encoder_mu = layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(encoder_flatten)\n",
        "    encoder_log_variance = layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(encoder_flatten)\n",
        "    encoder_output = layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
        "    \n",
        "    encoder = keras.models.Model(encoder_input, encoder_output, name=\"encoder_model\")\n",
        "    # encoder.summary()\n",
        "    \n",
        "    #Decoder\n",
        "    decoder_input = layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
        "    decoder_dense_layer1 = layers.Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
        "    decoder_reshape = layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
        "    decoder_output = layers.LeakyReLU(name=\"decoder_output\")(decoder_reshape)\n",
        "    decoder = keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
        "    # decoder.summary()\n",
        "    \n",
        "    # VAE\n",
        "    vae_input = layers.Input(shape=input_shape, name=\"VAE_input\")\n",
        "    vae_encoder_output = encoder(vae_input)\n",
        "    vae_decoder_output = decoder(vae_encoder_output)\n",
        "    vae = keras.models.Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
        "    # vae.summary()\n",
        "    vae = vae.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss_func(encoder_mu, encoder_log_variance))\n",
        "    print(autoencoder.layers[encoder_mu].weights)\n",
        "    return vae"
      ],
      "metadata": {
        "id": "E8C79u-FMmOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder(1)"
      ],
      "metadata": {
        "id": "tDwd7zWMNF-3",
        "outputId": "a7ce6a73-e919-4e09-86ba-5474314a843f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-954db3463c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-0506b2086200>\u001b[0m in \u001b[0;36mautoencoder\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# vae.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_log_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'layers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block:\n",
        "    ## import dataset\n",
        "    # data = \n",
        "    # x_train\n",
        "    # x_test\n",
        "    vae_1 = autoencoder(1).fit(x_train, x_train, epochs=20, batch_size=500, shuffle=True, validation_data=(x_test, x_test))\n",
        "    vae_2 = autoencoder(2).fit(x_train, x_train, epochs=20, batch_size=1 , shuffle=True, validation_data=(x_test, x_test))\n",
        "    vae_3 = autoencoder(2).fit(x_train, x_train, epochs=20, batch_size=1 , shuffle=True, validation_data=(x_test, x_test))\n",
        "    vae_4 = autoencoder(2).fit(x_train, x_train, epochs=20, batch_size=1 , shuffle=True, validation_data=(x_test, x_test))\n",
        "    vae_5 = autoencoder(2).fit(x_train, x_train, epochs=20, batch_size=1 , shuffle=True, validation_data=(x_test, x_test))\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "4Xc8fMIINLR0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}